// A simple feed-forward neural network described in TEL
module ffnn

// Universal data type for data flow
type float32

// Parameter declarations
W1: param[4x4] = random(0.0, 1.0)
W2: param[8x8] = random(0.0, 1.0)
W3: param[8x8] = random(0.0, 1.0)
b1: param[4x1] = 0.0
b2: param[8x1] = 0.0
b3: param[8x1] = 0.0

// Input layer 1
i1: in[4x1]
// Input layer 2
i2: in[4x1]

// Hidden layers
h1: hidden[4x1] = sigmoid(W1 • i1 + b1)
h2: hidden[8x1] = tanh(W2 • (1 - [h1, i2]) + b2)

// Output layer
o: out[1x8] = softmax(W3 • h2 + b3) as [1x8]
