trainable XOR<B> {
    var W1: float[2 x 5]
    var b1: float[1 x 5]
    var W2: float[5 x 1]
    var b2: float[1 x 1]
}

impl XOR {

    init() {

    }

    inference(x: float[Bx2]) -> float[Bx1] {
        let h1 = sigmoid(x . W1 + b1)
        return softmax(h1 . W2 + b2)
    }

    loss<k*>(reference: float[k], actual: float[k]) -> float {
        return reduce (reference - actual)^2 using mean
    }

    optimize<k*>(weight: float[k], gradient: float[k], learningRate: float) -> float[k] {
        return weight - gradient * learningRate
    }

}
