// RUN: dlopt -f %s -p AD --print-ir | FileCheck %s

// CHECK: AD: changed

module "mnist"
stage raw

// Simple scalar test (x * w + b)

func @scalar_simp: (f32, f32, f32) -> f32 {
'entry(%x: f32, %w: f32, %b: f32):
    %0.0 = multiply %x: f32, %w: f32
    %0.1 = add %0.0: f32, %b: f32
    return %0.1: f32
}

[gradient @scalar_simp]
func @scalar_simp_dxwb: (f32, f32, f32) -> (f32, f32, f32)

[gradient @scalar_simp wrt 1, 2]
func @scalar_simp_dwb: (f32, f32, f32) -> (f32, f32)

[gradient @scalar_simp wrt 1, 2 keeping 0]
func @scalar_simp_dwb_keeping: (f32, f32, f32) -> (f32, f32, f32)

[gradient @scalar_simp wrt 1, 2 seedable]
func @scalar_simp_dwb_seedable: (f32, f32, f32, f32) -> (f32, f32)

// Simple tensor test (x â€¢ w + b)

func @tensor_simp: (<1 x 784 x f32>, <784 x 10 x f32>, <1 x 10 x f32>) -> <1 x 10 x f32> {
'entry(%x: <1 x 784 x f32>, %w: <784 x 10 x f32>, %b: <1 x 10 x f32>):
    %0.0 = dot %x: <1 x 784 x f32>, %w: <784 x 10 x f32>
    %0.1 = add %0.0: <1 x 10 x f32>, %b: <1 x 10 x f32>
    return %0.1: <1 x 10 x f32>
}

[gradient @tensor_simp]
func @tensor_simp_dxwb: (<1 x 784 x f32>, <784 x 10 x f32>, <1 x 10 x f32>)
                       -> (<1 x 784 x f32>, <784 x 10 x f32>, <1 x 10 x f32>)

[gradient @tensor_simp wrt 1, 2]
func @tensor_simp_dwb: (<1 x 784 x f32>, <784 x 10 x f32>, <1 x 10 x f32>)
                      -> (<784 x 10 x f32>, <1 x 10 x f32>)

[gradient @tensor_simp wrt 1, 2 keeping 0]
func @tensor_simp_dwb_keeping: (<1 x 784 x f32>, <784 x 10 x f32>, <1 x 10 x f32>)
                              -> (<784 x 10 x f32>, <1 x 10 x f32>, <1 x 10 x f32>)

[gradient @tensor_simp wrt 1, 2 seedable]
func @tensor_simp_dwb_seedable: (<1 x 784 x f32>, <784 x 10 x f32>, <1 x 10 x f32>, <1 x 10 x f32>)
                               -> (<784 x 10 x f32>, <1 x 10 x f32>)
